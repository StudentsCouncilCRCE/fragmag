---
index: 8
section: technical
title: So the other day AI asked:What is Love?
class: TE IT
author: Sahil Gupta
endpoint: /so-the-other-day-ai-asked-what-is-love
---

When I started with machine learning, I was quite disappointed with how all these ML algorithms are trained to understand a problem and find out how we as humans solve the same, in fact in some cases the solutions are unconventional but unexpectedly accurate. But when you take a deeper look at these algorithms, it is quite obvious to realize that the approach is more like objective-based learning which is far from how the real world works i.e. subjective model, which solely depends on the scenario based decisions what we make and how a person as an individual feels about something, and this is quite a legit definition of being conscious.

Don’t get me wrong on this, all the achieved milestones with these algorithms are exceptional in a true sense. One of the articles I read, states that the trained Convolution model on the pictures of criminals having a neutral face in most of the images can predict if the person is criminal or not by extracting the facial details during interrogation with 83% of accuracy. And there is a considerable amount of amazing models ready to use in all kinds of domains. But let’s now think above all this, where exactly are we going? To make it simpler, take the Internet of Things (IoT) as an analogy to understand how objective-based models can help in subjective learning. Think of these ML algorithms as sensors used in IoT, as an interface with the real world, the working principle of these sensors has its own complexity and some error rate, same goes to machine learning models, they are trained for the specific task and have some error rate. Later in IoT, all the collected data is sent to the backbone of the system where the decisions are made, but in case of making machines think like humans the backbone is still missing, the consciousness, and this is what AI is all about.

Understanding AI is more like a study about humans than the technology. We as a human, our system consists of biological and emotional hormones which work simultaneously. Rather than writing programs that try to mimic specific human behaviours like love, we have to build machines that learn and develop the way humans do. This multidisciplinary field is called developmental robotics. The whole idea is to fill the gap of subjective learning and make a true humanoid. One of the approaches to develop consciousness is to allow a robot to self stimulate and become aware of itself, once that is done we can assign an objective task to it with bare minimum rules unlike many machine learning algorithms and let it learn by trial and error. Now, can we make it behave like a human? Human sadness is often linked to slower-paced speech, sluggish body movement. Anger, on the other hand, is generally associated with intense, abrupt speech and quick, aggressive movements. Emotional robots may be able to communicate with us in ways we intuitively understand, like showing a sluggish walk when their battery needs recharging, instead of a confusing panel of lights and beeps, modulate voice when it feels sorrow or anger.

In the recent interview of Hooman Samani, a director of the Artificial Intelligence and Robotics Technology Laboratory at National Taipei University, Taiwan says, “We tried to mimic that in our robot. For example, an increased level of ghrelin (a biological hormone) makes you feel hungry. Digital ghrelin makes the robot want to charge its battery, and from the physiological standpoint, oxytocin is the hormone of love. Its level increases when we interact with our beloved ones. It decreases when we are deprived of this interaction.”

To make this AI work, we move from a statistical approach to probability based approach specifically towards Baye’s probability which calculates the dependent/conditional probability. This gives us the ability to do risk assessment which is widely used in autonomous cars. The Bayesian approach can be easily understood by thinking of how we should classify a spam email from a bunch of emails. The idea is to find the probability of being spam given the words used in the mail by already knowing the probability of words used in a mail given that the mail is spam. But to make this more efficient, to mimic the emotional hormones of human body researcher use “Dynamic Bayesian Networks” or DBNs. Now, robots can dynamically (on real-time) understand how the inputs should be interpreted and decide what is the best reply or action to be taken which has minimal risk. So without any hesitation, an autonomous vehicle will kill a rabbit and save a human being if it had only option to save any one living being. To all the rabbit out there, stay safe, stay home. We, humans, are too mean to be alive.

All this does work amazingly, no doubt. These cutting edge findings do enable robots to understand us and give an appropriate response which might sound emphatically correct to us but do they really understand us? Can they build an image of each individual they interact with? In a way, what I am asking here is, when we talk to someone we use our knowledge and experiences to interpret the message and reply with our opinion on the subject. When we meet someone for the first time it is us who decide or guess if the opposite person is of “my type” or not. There is a huge amount of research and funds invested in this field which is known as “Cognitive robotics”. But till then the question still remained unanswered, can we make a robot understand ‘what is love?’
